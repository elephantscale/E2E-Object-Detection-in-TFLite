{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_Object_Detection_with_TFLite.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephantscale/E2E-Object-Detection-in-TFLite/blob/master/colab_training/Tutorial_Object_Detection_with_TFLite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyYfJF3yUhw7"
      },
      "source": [
        "# Tutorial: Object Detection with TFLite\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Imagine that you have a niece or a nephew and you want to give them a present.\n",
        "When you were growing up, your ant gave you a \"Find the Duck\" book. You had lots of fun\n",
        "finding the duck on every page of this board book. Today, you want to make this book\n",
        "into a computer game. For that, you need to be able to teach the computer how to find\n",
        "the duck. This is what this tutorial will teach you.\n",
        "\n",
        "<img src=\"find-the-duck-50.png\"/>\n",
        "\n",
        "## Our plan\n",
        "\n",
        "The task that you are about to undertake is called \"Object Detection.\" The good news is that the\n",
        "Google library called TensorFlow already does most of the groundwork for object detection.\n",
        "Furthermore, the TensorFlow Lite part of the library will help you to put your application on a\n",
        "phone or a device app. The end result of your object detection will look like a screenshot below,\n",
        "where you will be able to detect, out of a known set of objects, which ones are present\n",
        "in our picture and what are their locations.\n",
        "\n",
        "<img src=\"object-detection.png\"/>\n",
        "\n",
        "We will do it in three steps. First, you will have to prepare the data: those objects that you will be looking to identify.\n",
        "After you got the objects, you will have to convert them to TFrecord format that Object Detection API expects.\n",
        "Then, you will train the model with this data. And finally, you will export the model\n",
        "to TFLite, preparing it to be used in your phone app. In the next tutorial,\n",
        "we will teach you how to use the resulting TFLite model in your phone app. So, let us start."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ynDtloV1DyJ"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "Dataset homepage: https://www.kaggle.com/mbkinaci/fruit-images-for-object-detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd1bUjXKhkiB"
      },
      "source": [
        "!wget https://github.com/elephantscale/E2E-Object-Detection-in-TFLite/raw/master/data/Fruit_Images_for_Object_Detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr8o4K8NjhQu"
      },
      "source": [
        "!unzip -qq Fruit_Images_for_Object_Detection.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyFfc8-T1dIr"
      },
      "source": [
        "## Generate intermediate files\n",
        "\n",
        "To be able to generate TFRecords from our fruits dataset we first generate a `.csv` file that would contain the following fields - \n",
        "- filename\n",
        "- width\n",
        "- height\n",
        "- class\n",
        "- xmin\n",
        "- ymin\n",
        "- xmax\n",
        "- ymax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0mImtXzj0RE"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/elephantscale/E2E-Object-Detection-in-TFLite/master/colab_training/xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKlcf5IUkdJz"
      },
      "source": [
        "!python xml_to_csv.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQZmcTglsLy"
      },
      "source": [
        "!head -5 /content/train_zip/train_labels.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg7kvco7mZLA"
      },
      "source": [
        "!head -5 /content/test_zip/test_labels.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb9BwGlR19Ww"
      },
      "source": [
        "Now that we have `.csv` files we can do some basic exploratory data analysis (EDA) to better understand the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr3tSXiCoK36"
      },
      "source": [
        "## Basic EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTJfUh2pm4c0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3URS71koW1H"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/train_zip/train_labels.csv\")\n",
        "test_df = pd.read_csv(\"/content/test_zip/test_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtBt_AYjogIE"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsIwA7wMohwe"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvdTLpmhojKM"
      },
      "source": [
        "train_df[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4lMIKB_oncV"
      },
      "source": [
        "test_df[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSSRljJMoqZ9"
      },
      "source": [
        "def show_images(df, is_train=True):\n",
        "    if is_train:\n",
        "        root = \"/content/train_zip/train\"\n",
        "    else:\n",
        "        root = \"/content/test_zip/test\"\n",
        "    plt.figure(figsize=(15,15))\n",
        "    for i in range(10):\n",
        "        n = np.random.choice(df.shape[0], 1)\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(True)\n",
        "        image = plt.imread(os.path.join(root, df[\"filename\"][int(n)]))\n",
        "        plt.imshow(image)\n",
        "        label = df[\"class\"][int(n)]\n",
        "        plt.xlabel(label)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGcjO2ripKdR"
      },
      "source": [
        "show_images(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Di0_rOpMV0"
      },
      "source": [
        "show_images(test_df, is_train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc-TTag0pp5q"
      },
      "source": [
        "def verify_annotations(df, is_train=True):\n",
        "    if is_train:\n",
        "        root = \"/content/train_zip/train\"\n",
        "    else:\n",
        "        root = \"/content/test_zip/test\"\n",
        "    \n",
        "    plt.figure(figsize=(12,12))\n",
        "    for i in range(3):\n",
        "        n = np.random.choice(df.shape[0], 1)\n",
        "        plt.subplot(1,3,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        \n",
        "        image = plt.imread(os.path.join(root, df[\"filename\"][int(n)]))\n",
        "        xmin, ymin = int(df[\"xmin\"][int(n)]), int(df[\"ymin\"][int(n)])\n",
        "        xmax, ymax = int(df[\"xmax\"][int(n)]), int(df[\"ymax\"][int(n)])\n",
        "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255,0,0), 3)\n",
        "        plt.imshow(image)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ZMF5w0rAS-"
      },
      "source": [
        "verify_annotations(train_df, is_train=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTky5iU9rHpT"
      },
      "source": [
        "verify_annotations(test_df, is_train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HrBfhYfeNjt"
      },
      "source": [
        "As we can see the dataset has annotation issues. So, our model training can suffer a lot from this. So, one can expect a model trained on this dataset might yield unexpected results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5-TguVVzNJd"
      },
      "source": [
        "## Generate TFRecords and `.pbtxt`\n",
        "\n",
        "Explaining the steps of creating TFRecords is out of scope here. Please follow this Kaggle kernel that sheds some light on the process. \n",
        "\n",
        "The utility scripts that I used in the following cells were adapted from [this repository](https://github.com/anirbankonar123/CorrosionDetector). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aT-AJsosHZq"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)\n",
        "\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "% cd models/research\n",
        "!pip install --upgrade pip\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf1/setup.py .\n",
        "!python -m pip install --use-feature=2020-resolver ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umlUy7GOtFRZ"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/elephantscale/E2E-Object-Detection-in-TFLite/master/colab_training/generate_tfrecord.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijp-_gvswPjv"
      },
      "source": [
        "!python generate_tfrecord.py \\\n",
        "    --csv_input=/content/train_zip/train_labels.csv \\\n",
        "    --output_path=/content/train_zip/train.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTp_KcrXxgON"
      },
      "source": [
        "Before the running the cell below please edit the `path` variable in the `main()` function of `generate_tfrecord.py`. `generate_tfrecord.py` should be located here - `/content/models/research`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5I_eRHtwigV"
      },
      "source": [
        "!python generate_tfrecord.py \\\n",
        "    --csv_input=/content/test_zip/test_labels.csv \\\n",
        "    --output_path=/content/test_zip/test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbRvRmDBx9NC"
      },
      "source": [
        "!pwd\n",
        "!ls -lh /content/test_zip/*.record\n",
        "!ls -lh /content/train_zip/*.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LNIRZQizwwu"
      },
      "source": [
        "Be sure to store these `.record` files to somewhere safe. Next, we need to generate a `.pbtxt` file that defines a mapping between our classes and integers. In the `generate_tfrecord.py` script, we used the following mapping - \n",
        "\n",
        "```python\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'orange':\n",
        "        return 1\n",
        "    elif row_label == 'banana':\n",
        "        return 2\n",
        "    elif row_label == 'apple':\n",
        "        return 3\n",
        "    else:\n",
        "    \treturn None\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiveLk4m0Gbb"
      },
      "source": [
        "label_encodings = {\n",
        "    \"orange\": 1,\n",
        "    \"banana\": 2,\n",
        "    \"apple\": 3\n",
        "}\n",
        "\n",
        "f = open(\"/content/label_map.pbtxt\", \"w\")\n",
        "\n",
        "for (k, v) in label_encodings.items():\n",
        "    item = (\"item {\\n\"\n",
        "            \"\\tid: \" + str(v) + \"\\n\"\n",
        "            \"\\tname: '\" + k + \"'\\n\"\n",
        "            \"}\\n\")\n",
        "    f.write(item)\n",
        "\n",
        "f.close()\n",
        "\n",
        "!cat /content/label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M29rUmj0wKb"
      },
      "source": [
        "Be sure to save this file as well. Next we will proceed toward training a custom detection model with what we have so far. Follow the steps in [this notebook](https://colab.research.google.com/github/sayakpaul/E2E-Object-Detection-in-TFLite/blob/master/colab_training/Training_MobileDet_Custom_Dataset.ipynb)."
      ]
    }
  ]
}